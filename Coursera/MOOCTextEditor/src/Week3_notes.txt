Data Structures and Performance - Week 3 Notes

Strategy for calculating performance:
	1.	Count the amount of operations instead of time
	2.	Focus on how performance scales (bigger input)
	3.	Go beyond input size (how does the algorithm react to different situations)
	
Asymptotic Analysis: 

	Size of input is represented by letter N.
	Constant time = no change related to size of input.
	linear time: the amount of operations grows incrementally when the input is bigger
	Asymptotic Analysis is not the only measure of performance
	
Big O classes:
	f(n) = O (g(n)) means both functions grow as their input grows.
	Big O notation captures the rate of growth of two functions
	Principles: 
	-	Drop constants -> we don't care about the constants that are always required (like initializing the process)
	-	Keep only the dominant term -> only interested in the part which has the biggest impact when input changes (fastest growing)
		3n+3 = O(3n) = O(n)
	Computing multiple functions
	-	Adding of big O -> O(n) + O(n) = O(2n) = O(n) (drop constants)
	Computing nested functions:
	-	start from the inside out
	-	Multiplication of big O -> O(n) * O(n) = O(n^2)
		
	1.	O(1), O(log n)	-	best performance (base of logarithm does not matter!)
	2.	O(n)
	3.	O(n log n)
	4.	O(n^2)
	5.	O(2^n)
	6.	O(n!)			-	worst performance
	
	Performance
	Worst case:	worst possible performance of fixed size n
	Average case: Average possible performance of any size of n
	Best case: Best possible performance of algorithm for any input (of fixed size n)
	
	Search algorithms:	best case	|	worst case
	linear search			O(1)	|		O(n)
	binary search			O(1)	|		O(log n) each time we half the list
	
	Sorting algorithms:	best case	|	worst case
	selection sort			O(n^2)	|		O(n^2)	always goes through the same process (nested loop)
	insertion sort			O(n)	|		O(n^2)
	Merge Sort				O(n log n)		O(n log n)
	
Selection Sort	strategy is going to look at each position in the array in turn. And for each of those positions, 
				find the right element to put in there. And so we look at all of the possible elements remaining in the array. 
				And figure out which one of those is smallest and put it in this current position.
Insertion Sort	Check one new element of the array at a time. For that new element put it in its correct location relative 
				to the earlier ones that have been sorted already. We assume that at each point we have that initial piece of 
				the arrays already sorted. What we need to do is figure out where the next element goes by comparing that 
				next element to the highest element in the sorted part of the array and see if we need to swap them
Merge Sort -> 	build in sort method with Collections.sort(list)
				If list is one object, return list, else
				divide list in two parts continuously, sort both lists, merge lists into one list
				
Bench Marking: measuring time of two different programs on the same system, or the same program on two different systems.
	nanoTime() is build in JAVA time returning a long displaying JAVA Virtual Machine high resolution time source in nanoSeconds.
				long startTime = System.nanoTime(); long endTime = System.nanoTime();
				double estTime = (endTime - startTime) / 100000000.0 ;
	
Cheat sheet
List                 | Add  | Remove | Get  | Contains | Next | Data Structure
---------------------|------|--------|------|----------|------|---------------
ArrayList            | O(1) |  O(n)  | O(1) |   O(n)   | O(1) | Array
LinkedList           | O(1) |  O(1)  | O(n) |   O(n)   | O(1) | Linked List
CopyOnWriteArrayList | O(n) |  O(n)  | O(1) |   O(n)   | O(1) | Array



Set                   |    Add   |  Remove  | Contains |   Next   | Size | Data Structure
----------------------|----------|----------|----------|----------|------|-------------------------
HashSet               | O(1)     | O(1)     | O(1)     | O(h/n)   | O(1) | Hash Table
LinkedHashSet         | O(1)     | O(1)     | O(1)     | O(1)     | O(1) | Hash Table + Linked List
EnumSet               | O(1)     | O(1)     | O(1)     | O(1)     | O(1) | Bit Vector
TreeSet               | O(log n) | O(log n) | O(log n) | O(log n) | O(1) | Red-black tree
CopyOnWriteArraySet   | O(n)     | O(n)     | O(n)     | O(1)     | O(1) | Array
ConcurrentSkipListSet | O(log n) | O(log n) | O(log n) | O(1)     | O(n) | Skip List



Queue                   |  Offer   | Peak |   Poll   | Remove | Size | Data Structure
------------------------|----------|------|----------|--------|------|---------------
PriorityQueue           | O(log n) | O(1) | O(log n) |  O(n)  | O(1) | Priority Heap
LinkedList              | O(1)     | O(1) | O(1)     |  O(1)  | O(1) | Array
ArrayDequeue            | O(1)     | O(1) | O(1)     |  O(n)  | O(1) | Linked List
ConcurrentLinkedQueue   | O(1)     | O(1) | O(1)     |  O(n)  | O(n) | Linked List
ArrayBlockingQueue      | O(1)     | O(1) | O(1)     |  O(n)  | O(1) | Array
PriorirityBlockingQueue | O(log n) | O(1) | O(log n) |  O(n)  | O(1) | Priority Heap
SynchronousQueue        | O(1)     | O(1) | O(1)     |  O(n)  | O(1) | None!
DelayQueue              | O(log n) | O(1) | O(log n) |  O(n)  | O(1) | Priority Heap
LinkedBlockingQueue     | O(1)     | O(1) | O(1)     |  O(n)  | O(1) | Linked List



Map                   |   Get    | ContainsKey |   Next   | Data Structure
----------------------|----------|-------------|----------|-------------------------
HashMap               | O(1)     |   O(1)      | O(h / n) | Hash Table
LinkedHashMap         | O(1)     |   O(1)      | O(1)     | Hash Table + Linked List
IdentityHashMap       | O(1)     |   O(1)      | O(h / n) | Array
WeakHashMap           | O(1)     |   O(1)      | O(h / n) | Hash Table
EnumMap               | O(1)     |   O(1)      | O(1)     | Array
TreeMap               | O(log n) |   O(log n)  | O(log n) | Red-black tree
ConcurrentHashMap     | O(1)     |   O(1)      | O(h / n) | Hash Tables
ConcurrentSkipListMap | O(log n) |   O(log n)  | O(1)     | Skip List